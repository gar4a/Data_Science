{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx-bEiPmwa-8"
      },
      "source": [
        "**Fake Job Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qoot2spX9GI"
      },
      "source": [
        "Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymAUc-vTwwPS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWz_z6xKF9gp"
      },
      "source": [
        "# Web Scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvmYayLpZF-u",
        "outputId": "e7ee5579-c761-4093-e43f-78e8fea75889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Web Scrapping done!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Define the locations and job search keywords\n",
        "#locations = [\n",
        "    # Asia\n",
        "    #Mumbai', 'Delhi', 'Bangalore', 'Hyderabad', 'Ahmedabad', 'Chennai', 'Kolkata','Hong Kong',\n",
        "    # Africa\n",
        "     #'Johannesburg', 'Cape Town', 'Nairobi','Accra','Kampala','Addis Ababa', 'Durban', 'Pretoria', 'Kimberley'\n",
        "#]\n",
        "#job_search_keywords = [\n",
        "    # Tech industry\n",
        "    #'Data+Scientist', 'Software+Engineer', 'Full+Stack+Developer', 'Front+End+Developer', 'Back+End+Developer',\n",
        "    #'DevOps+Engineer', 'Database+Administrator', 'Data+Analyst',\n",
        "    # Finance industry\n",
        "    #'Financial+Analyst', 'Accountant', 'Financial+Advisor', 'Auditor', 'Insurance+Agent',\n",
        "    #'Investment+Banker', 'Tax+Consultant', 'Budget+Analyst', 'Cost+Estimator', 'Loan+Officer',\n",
        "    # Healthcare industry\n",
        "    #'Nurse', 'Physician', 'Pharmacist', 'Dietitian', 'Physical+Therapist',\n",
        "    #'Radiologic+Technologist', 'Medical+Technologist', 'Home+Health+Aide', 'Medical+Transcriptionist', 'Phlebotomist',\n",
        "    # Education industry\n",
        "    #'Teacher', 'Teaching+Assistant',\n",
        "    #'Childcare+Worker',  'Preschool+Teacher', 'College+Counselor', 'School+Psychologist',\n",
        "    # Marketing industry\n",
        "    #'Marketing+Manager', 'SEO+Specialist', 'Content+Marketing+Manager', 'Brand+Manager', 'Public+Relations+Specialist',\n",
        "    #'Media+Planner', 'Product+Manager', 'Digital+Marketing+Manager', 'Social+Media+Manager', 'Marketing+Analyst'\n",
        "#]\n",
        "locations = ['USA']\n",
        "job_search_keywords = ['Business+Analyst']\n",
        "# Loop through each location and job search keyword and extract the job data\n",
        "job_data = []\n",
        "for location in locations:\n",
        "    for job_search_keyword in job_search_keywords:\n",
        "        # Define the URL of the job search page\n",
        "        url = f'https://www.linkedin.com/jobs/search/?keywords={job_search_keyword}&location={location}'\n",
        "\n",
        "        # Send a GET request to the URL and store the response\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Parse the HTML content of the response using Beautiful Soup\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all the job listings on the page\n",
        "        #job_listings = soup.find_all('li', class_='job-search-card')\n",
        "\n",
        "        # print(soup)\n",
        "        # Find all of the job listings on the page\n",
        "        job_listings = soup.find_all(class_='job-search-card')\n",
        "        # For each job listing, extract the title, company, and location\n",
        "        for i, listing in enumerate(job_listings):\n",
        "            title = listing.find('h3').text.strip()\n",
        "            company = listing.find('h4').text.strip()\n",
        "            location = listing.find('span', class_='job-search-card__location').text.strip()\n",
        "            job_link = listing.find(\"a\", href=True)[\"href\"]\n",
        "            resp = requests.get(job_link)\n",
        "            soup=BeautifulSoup(resp.text,'html.parser')\n",
        "            #time.sleep(5)  # Pause to avoid overwhelming the server\n",
        "            job_criteria_list = soup.find(\"ul\", {\"class\": \"description__job-criteria-list\"})\n",
        "            if job_criteria_list:\n",
        "               job_criteria = job_criteria_list.find_all(\"li\")\n",
        "            else:\n",
        "               break\n",
        "            try:\n",
        "                level=job_criteria[0].text.replace(\"Seniority level\",\"\").strip()\n",
        "            except:\n",
        "                level=None\n",
        "            try:\n",
        "                empType=job_criteria[1].text.replace(\"Employment type\",\"\").strip()\n",
        "            except:\n",
        "                empType=None\n",
        "            try:\n",
        "                empFunction=job_criteria[2].text.replace(\"Job function\",\"\").strip()\n",
        "            except:\n",
        "                empFunction=None\n",
        "            try:\n",
        "                industries=job_criteria[3].text.replace(\"Industries\",\"\").strip()\n",
        "            except:\n",
        "                industries=None\n",
        "            try:\n",
        "                salary=soup.find(\"div\", {\"class\": \"salary compensation__salary\"}).text.strip()\n",
        "            except:\n",
        "                salary=None\n",
        "\n",
        "            job_data.append({'job_id':i, 'title': title, 'location': location , 'department':None, 'salary_range': salary ,\n",
        "                             'company_profile':company,'description':None, 'requirements':None, 'benefits':None,\n",
        "                             'telecommuting':0 ,'has_company_logo':0 , 'has_questions':0 , 'employment_type': empType,\n",
        "                             'required_experience': level,'required_education':None,'industry': industries,\n",
        "                             'function': empFunction , 'fraudulent':0 })\n",
        "            # Define the file name and header row\n",
        "\n",
        "# Convert the job data to a pandas DataFrame\n",
        "df_linkedin = pd.DataFrame(job_data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_linkedin.to_csv('jobs_linkedin.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Web Scrapping done!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3D_gVRmw6Ps"
      },
      "source": [
        "# Importing DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "iaqC7fX-xJQ0",
        "outputId": "6ecccb19-6ef0-4bc2-a36a-bdc230154500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://uofi.box.com/shared/static/sfw0eqvj7q49vmexpztqke7xzhspevnb.csv\n",
            "50061601/50061601 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17880,\n  \"fields\": [\n    {\n      \"column\": \"job_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5161,\n        \"min\": 1,\n        \"max\": 17880,\n        \"num_unique_values\": 17880,\n        \"samples\": [\n          4709,\n          11080,\n          12358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11231,\n        \"samples\": [\n          \"Environmental Lab Technician\",\n          \"Junior Designer\",\n          \"Case Handler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3105,\n        \"samples\": [\n          \"US, VA, Arlington\",\n          \"US, AL, Dothan\",\n          \"US, CA, Long Beach\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          \"Finance team\",\n          \"Product Ops\",\n          \"Engineering - Hardware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary_range\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 874,\n        \"samples\": [\n          \"60000-130000\",\n          \"30000-450000\",\n          \"120000-130000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company_profile\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1709,\n        \"samples\": [\n          \"WHY WORK AT IMAGINET\\u00a0\\u201cWorking at Imaginet is great! I get to work with leading edge technology as well as the some of the best developers, project managers and management in the industry.\\u201d\\u00a0-- Evan Bosscher, Application Developer at Imaginet\\u201cImaginet enables me to use the latest tools and platforms to solve complex and challenging problems and encourages me to continue growing in my application development career.\\u00a0 My peers at Imaginet are some of the best and brightest developers in the country.\\u201d\\u00a0-- Tyler Doerksen, Cloud Application Specialist at Imaginet\\u00a0At Imaginet, our clients look to us to help them with their toughest projects using the newest technologies.\\u00a0 We are the technology partner who tames their chaos, who turns disruption into steady state and makes the unknown more predictable.\\u00a0 We are at the forefront of emerging technology trends, new product releases and shifts in the software development industry.\\u00a0 We are constantly learning about, and experimenting with the latest and greatest software platforms, controls, processes and design patterns.\\u00a0Our current projects include:\\u2022\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 Enterprise Mobility \\u2022\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 Dev Ops \\u2022\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 Business Intelligence \\u2022\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 Scrum/Lean/Kanban \\u2022\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 Enterprise Content ManagementIf you are passionate about being part of a leading edge software development team with a commitment to continuous learning, we want you as part of the Imaginet team.BalancePeople lead dynamic lives and not all personal commitments lie outside of 9-5.\\u00a0 At Imaginet, we recognize that our employees need the flexibility to support their families, hobbies, charities, and other interests to stay motivated and fulfilled.\\u00a0 Many employees work partially from home, start/stop work at different times or telecommute from a home office.\\u00a0 At Imaginet, it is passion and performance that counts, not which hours in the day you sit in the office.Personal DevelopmentWe want the best and brightest minds working with us.\\u00a0 Our employees are recognized thought leaders in software development and we encourage continued learning.\\u00a0Imaginet employees who wish to write exams are subsidized upon the completion of technical certifications and can receive raises for exemplary results.\\u00a0 We fund and encourage our employee\\u2019s participation at conferences with special interest in those who can speak on niche software development topics and practices. Imaginet has more Microsoft MVPs on staff per capita than any other Microsoft partner and we encourage employees to attend the MVP summits at Microsoft in Redmond.\\u00a0 Imaginet employees are very active in the local software community and lead .NET user groups in many of our employees residing cities.\\u00a0 We also encourage our employees to present internally via \\u201clunch and learns\\u201d on topics of interest.Compensation\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0Even though Imaginet is a great place to work, it\\u2019s still a job and you want to be paid.\\u00a0 We pride ourselves on our \\u2018promote from within\\u2019 philosophy and provide competitive compensations. We provide excellent health care benefits including eye, dental and disability.\\u00a0 We also offer overtime to our employees that want to work extra hours on select projects.Recognized LeadersImaginet is globally recognized within the software industry as a premier consulting and software development organization.\\u00a0 We are a multiple Microsoft Gold Partner, Telerik Gold Partner, #URL_eb33f3e87ac1203366e8701171cb1ef8a42857099f85613b3b7f029ffb751723# Partner and a founding member of the Lean Kanban University.\\u00a0\\u00a0 We are invited to speak at conferences around the world and have published numerous books under Microsoft Press.\\u00a0 In addition, we have many Microsoft MVPs, Virtual Technical Specialists (VTSs) and Regional Directors on staff.\\u00a0Our experience spans over 2,400 engagements, 1,100 clients, and over 17 years.\\u00a0 We are the world leaders in ALM on the Microsoft platform and 1st Ever Winner of the Global Microsoft Partner of the Year Award in ALM.\",\n          \"Bluesmart is an early stage startup that is re-defining the way that we travel. We are currently in stealth mode, but we are planning to unveil our first product to the world very soon! We are a group of seasoned entrepreneurs with experience building companies in retail, travel, mobile applications, and product design. We are highly international, with our team splitting time between New York and Buenos Aires. Join us, and we guarantee that you will learn a lot, meet interesting people, and have fun at the same time.\",\n          \"Softomotive Ltd is a Software Development company located in Athens, Greece. We specialize in Process Automation software and our customers range from individual users to large Fortune500 companies all over the world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14801,\n        \"samples\": [\n          \"EvergiveEvergive was born from a simple desire to donate in search of an easy way to transact.From these simple roots, Evergive grew into a transformative platform that improves and enhances the entire fundraising ecosystem. Our goal is to help nonprofits be more successful in their mission by providing technology to support the donor lifecycle and to provide a better fundraising experience. Partners think of us as a mobile presence for their organization.Evergive is designed to keep individuals connected to the causes and organizations they support. Whether you support a church, a school, a community group or a friend's cause - Evergive simplifies and enhances giving.We are located near Caltrain in Palo Alto, CA and backed by some of Silicon Valley's top investors.Engagement Marketing ManagerThe right candidate for this position is a smart, outside-the-box thinker who is ready to create and implement marketing strategies and excited to analyze engagement to make smarter marketing decisions. We're looking for someone creative and independent who doesn't sleep until goals are accomplished.\\u00a0We love candidates who have overcome adversity and created something out of nothing.\\u00a0This is a position with a lot of potential for growth and ownership, helping define our brand, identity and strategy at our partner organizations.\\u00a0On a daily basis, you will...* Give updates on engagement per partner and progress against our goals* Keep in touch with the partners through calls and visits to make sure their program is on track* Construct creative marketing campaigns to increase awareness of the Evergive platform within our partner communities* Run user engagement at Evergive, constructing and testing the email notification system for donors* Writing the partner adoption playbook, ensuring that we track and measure how we launched a new account and never repeat something that doesn't work\",\n          \"To work on analytics modelling using desktop and programming tools (R, SPSS) on business data in a financial investment institution.\",\n          \"We\\u2019re hiring a talented full time in-house web developer to join our team at The Mobile Majority.Responsibilities include:Developing stunning web applications by writing pixel perfect code.Efficiently communicating current tasks, issues, and recommendations on front end development tasks.Effectively gathering user input and bug reports an push updates accordingly.The Mobile Majority is a rapidly growing ad tech startup based in Santa Monica,\\u00a0CA, with offices in New York City, San Francisco, Chicago, Sao Paolo and Ho Chi\\u00a0Min City. We have been honored as the 'Best Creative Technology' by the American\\u00a0Association of Advertising Agencies and won 'Best Series A' By the Los Angeles\\u00a0Venture Association.\\u00a0We have raised $21M, and do business with some of the biggest brands in the world (Chase Bank, Unilever, Paramount, Warner Brothers, State Farm Insurance, Hershey\\u2019s, Clorox and Time Warner Cable, to name a few).The Mobile Majority has a culture of engineering focused, data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. \\u00a0As a key member of a small and versatile team, you will be responsible to design, test, deploy and maintain software solutions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"requirements\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11968,\n        \"samples\": [\n          \"Minimum LPN (Licensed Practical Nurse) current license requiredMinimum\\u00a05 years\\u2019 experience as an LPNSolid computer skills (Microsoft applications) a MUSTMust be detail orientedKnowledge of MedWatch REQUIREDKnowledge of prescription medication, dietary supplements and common side effects of bothKnowledge of medical terminologyDemonstrated experience with Nutrition, elder care and quality improvement preferredStrong communication skills to communicate information verbally and in writing so that others can understandCustomer service skillsAbility to file and retrieve informationAbility to keep information confidentialAbility to interface with multiple levels of leadershipAbility to work independentlyAbility to multitask and work independentlyAbility to sit for long periods of timeAbility to lift 5 pounds\",\n          \"Significant experience with direct recruiting processes (not in a staffing firm), interview methods, and reference-checking.Organized and detail oriented but capable of prioritizing actions based on known objectives in any project.Self-starter capable of demonstrating the resourcefulness needed in a startup environment where objectives will change regularly.A good communicator capable of writing and speaking concisely and professionally with colleagues and external stakeholders.Experience running a small business or an office in a B2B business service environment desirable.Good skills using web-based applications, Google Apps, Google Docs, MS Word, MS Excel, and capable of quickly learning new tools.Comfortable working in a remote environment where colleagues may be located in multiple locations nationally.\",\n          \"Associates-level of experience. \\u00a0Company Overview:Our international client specializes in\\u00a0hi-tech transactional and technology services, consulting, systems integration, and managed services.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6205,\n        \"samples\": [\n          \"Attractive pay packageMobile allowanceTransportation allowancePersonal loansFlexible hoursMedical insuranceSocial insurancePaid vacationsSocial activitiesTraining &amp; developmentTuition assistanceProfit ShareCequens Team \\u00a0 \\u00a0 \\u00a0 \\u00a0 \\u00a0 \\u00a0 \\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0We believe in choosing the best\\u00a0calibers and assisting them in\\u00a0continuing to develop their\\u00a0potential and qualifications. A\\u00a0good working environment, the\\u00a0right motivation and great\\u00a0teamwork is the way we use to\\u00a0successfully achieve our goals.About usWe are\\u00a0a\\u00a0leading technology corporation that specializes in mobile messaging services and solutions. Serving hundreds of renowned customers in more than 40 countries worldwide, please visit our website\\u00a0#URL_414f2c0c30d37b5a8db0880b6d51f6b9b08fc03a22553f0d0a568b2687dc8e3e#\\u00a0to know more about us. \\u00a0\",\n          \"Competative Pay,Vacation,Sick Leave,Health Insurance\",\n          \"Health and Dental Insurance through UHC50% of premium paid by companyVision Plan through Advantica50% of premium paid by companyShort Term Disability through UNUM50% of premium paid by company.$25,000 A&amp;D life insurance paid 100% by the company.401K with company matching 100% up to the first 3%, and 50% on the 4% -5% contributions.\\u00a0 Immediately vested upon eligibilityEight paid holidays.\\u00a0 1 Floating holiday80 hours of PTO accrued during first year of employment.Flexible environmentFree drinks and snacksEmployee lounge with video gamesCasual dress (jeans)Plenty of fun activities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"telecommuting\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_company_logo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Full-time\",\n          \"Temporary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_experience\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Internship\",\n          \"Not Applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Vocational - Degree\",\n          \"Doctorate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 131,\n        \"samples\": [\n          \"Publishing\",\n          \"Music\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"Human Resources\",\n          \"Business Development\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fraudulent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ac98e91e-93ee-41af-b695-e83a7632f541\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "      <th>fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Marketing Intern</td>\n",
              "      <td>US, NY, New York</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
              "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
              "      <td>Experience with content management systems a m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>Internship</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Customer Service - Cloud Video Production</td>\n",
              "      <td>NZ, , Auckland</td>\n",
              "      <td>Success</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
              "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
              "      <td>What we expect from you:Your key responsibilit...</td>\n",
              "      <td>What you will get from usThrough being part of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing and Advertising</td>\n",
              "      <td>Customer Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
              "      <td>US, IA, Wever</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Valor Services provides Workforce Solutions th...</td>\n",
              "      <td>Our client, located in Houston, is actively se...</td>\n",
              "      <td>Implement pre-commissioning and commissioning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Account Executive - Washington DC</td>\n",
              "      <td>US, DC, Washington</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our passion for improving quality of life thro...</td>\n",
              "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
              "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
              "      <td>Our culture is anything but corporate—we have ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Bill Review Manager</td>\n",
              "      <td>US, FL, Fort Worth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
              "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
              "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
              "      <td>Full Benefits Offered</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Hospital &amp; Health Care</td>\n",
              "      <td>Health Care Provider</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac98e91e-93ee-41af-b695-e83a7632f541')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac98e91e-93ee-41af-b695-e83a7632f541 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac98e91e-93ee-41af-b695-e83a7632f541');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9db788c-de90-402b-9dfa-0a2e8b420143\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9db788c-de90-402b-9dfa-0a2e8b420143')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9db788c-de90-402b-9dfa-0a2e8b420143 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   job_id                                      title            location  \\\n",
              "0       1                           Marketing Intern    US, NY, New York   \n",
              "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
              "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
              "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
              "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
              "\n",
              "  department salary_range                                    company_profile  \\\n",
              "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
              "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
              "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
              "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
              "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
              "\n",
              "                                         description  \\\n",
              "0  Food52, a fast-growing, James Beard Award-winn...   \n",
              "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
              "2  Our client, located in Houston, is actively se...   \n",
              "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
              "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
              "\n",
              "                                        requirements  \\\n",
              "0  Experience with content management systems a m...   \n",
              "1  What we expect from you:Your key responsibilit...   \n",
              "2  Implement pre-commissioning and commissioning ...   \n",
              "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
              "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
              "\n",
              "                                            benefits  telecommuting  \\\n",
              "0                                                NaN              0   \n",
              "1  What you will get from usThrough being part of...              0   \n",
              "2                                                NaN              0   \n",
              "3  Our culture is anything but corporate—we have ...              0   \n",
              "4                              Full Benefits Offered              0   \n",
              "\n",
              "   has_company_logo  has_questions employment_type required_experience  \\\n",
              "0                 1              0           Other          Internship   \n",
              "1                 1              0       Full-time      Not Applicable   \n",
              "2                 1              0             NaN                 NaN   \n",
              "3                 1              0       Full-time    Mid-Senior level   \n",
              "4                 1              1       Full-time    Mid-Senior level   \n",
              "\n",
              "  required_education                   industry              function  \\\n",
              "0                NaN                        NaN             Marketing   \n",
              "1                NaN  Marketing and Advertising      Customer Service   \n",
              "2                NaN                        NaN                   NaN   \n",
              "3  Bachelor's Degree          Computer Software                 Sales   \n",
              "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
              "\n",
              "   fraudulent  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1st dataset ( main feed )\n",
        "jobs_file = tf.keras.utils.get_file(\n",
        "    fname=\"./fraudulent_jobs.csv\",\n",
        "    origin=\"https://uofi.box.com/shared/static/sfw0eqvj7q49vmexpztqke7xzhspevnb.csv\"\n",
        ")\n",
        "\n",
        "df=pd.read_csv(jobs_file)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zv4aAcTJYY7"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KSaFFRKpJVsi",
        "outputId": "3362f106-1b87-4521-8ae7-37316b532ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98      3395\n",
            "           1       1.00      0.12      0.21       181\n",
            "\n",
            "    accuracy                           0.96      3576\n",
            "   macro avg       0.98      0.56      0.59      3576\n",
            "weighted avg       0.96      0.96      0.94      3576\n",
            "\n",
            "Data generation done!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "df['full_text'] = df['title'] + \" \" + df['location'] + \" \" + df['department'] + \" \" + df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits']\n",
        "df['full_text'] = df['full_text'].fillna('')\n",
        "# Use TF-IDF to convert the text data into numerical data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['full_text'])\n",
        "\n",
        "# The 'fraudulent' column is the target variable\n",
        "y = df['fraudulent']\n",
        "\n",
        "# Split the data into a training set and a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier on the training data\n",
        "# Train a Random Forest Classifier on the training data with adjusted parameters\n",
        "model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Use the model to predict the 'fraudulent' column for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print a classification report to see how well the model performed\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Load the other dataset\n",
        "jobs_linkedin = pd.read_csv('/content/jobs_linkedin.csv')\n",
        "\n",
        "# Combine all the text data into a single column\n",
        "#combine all text into 1 column - full_text\n",
        "jobs_linkedin['full_text'] = jobs_linkedin['title'] + \" \" + jobs_linkedin['location'] + \" \" + jobs_linkedin['department'] + \" \" + jobs_linkedin['company_profile'] + \" \" + jobs_linkedin['description'] + \" \" + jobs_linkedin['requirements'] + \" \" + jobs_linkedin['benefits']\n",
        "jobs_linkedin['full_text'] = jobs_linkedin['full_text'].fillna('')\n",
        "\n",
        "# Use the same TF-IDF vectorizer to transform the text data into numerical data\n",
        "X_jobs_linkedin = vectorizer.transform(jobs_linkedin['full_text'])\n",
        "\n",
        "# Use the trained model to predict the 'fraudulent' column for the other dataset\n",
        "jobs_linkedin['fraudulent'] = model.predict(X_jobs_linkedin)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "jobs_linkedin.to_csv('jobs_linkedin_with_fraudulent.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Data generation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aLMW9GmVBLY"
      },
      "source": [
        "Upload Local File(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d5db16aa83304802a3e19aab154ab008",
            "1e2613cd0b1f4c5f9227000319e23bef",
            "5c5e293930f9484f9ca4a9560effcee0"
          ]
        },
        "id": "r4GbH4JUUVLS",
        "outputId": "6846eaa3-06ae-4786-ac83-4ca9a3d3362a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5db16aa83304802a3e19aab154ab008"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, FileLink\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Create a file upload widget\n",
        "upload_widget = widgets.FileUpload()\n",
        "\n",
        "# Display the upload widget\n",
        "display(upload_widget)\n",
        "\n",
        "# Define a function to handle the uploaded file\n",
        "def handle_upload(change):\n",
        "    uploaded_filename = next(iter(upload_widget.value))\n",
        "    content = upload_widget.value[uploaded_filename]['content']\n",
        "\n",
        "    # Write the content to a local file\n",
        "    local_filename = f'./{uploaded_filename}'\n",
        "    with open(local_filename, 'wb') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f'File {uploaded_filename} uploaded and saved as {local_filename}')\n",
        "\n",
        "# Attach the function to the widget's event\n",
        "upload_widget.observe(handle_upload, names='_counter')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9JI0FRsqVz8Q",
        "outputId": "c3b6bc23-c314-43aa-a14f-f7b857194e58"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/CompiledjobListNigeria.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bb0f8a196451>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import File from local memory after upload.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/CompiledjobListNigeria.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find the maximum value in the 'Code' column of df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CompiledjobListNigeria.csv'"
          ]
        }
      ],
      "source": [
        "# Import File from local memory after upload.\n",
        "df2=pd.read_csv('/content/CompiledjobListNigeria.csv')\n",
        "\n",
        "# Find the maximum value in the 'Code' column of df\n",
        "max_code = df['job_id'].max()\n",
        "\n",
        "# Check if 'job_id' column exists in df, and add it with index row if not\n",
        "if 'job_id' not in df2.columns:\n",
        "    df2['job_id'] = df2.reset_index().index\n",
        "\n",
        "# Check if 'ColumnName' column exists in df, and add it with index row if not\n",
        "if 'benefits' not in df2.columns:\n",
        "    df2['benefits'] = None\n",
        "\n",
        "# Check if 'ColumnName' column exists in df, and add it with index row if not\n",
        "if 'function' not in df2.columns:\n",
        "    df2['function'] = None\n",
        "\n",
        "# Check if 'ColumnName' column exists in df, and add it with index row if not\n",
        "if 'industry' not in df2.columns:\n",
        "    df2['industry'] = None\n",
        "\n",
        "# Check if 'ColumnName' column exists in df, and add it with index row if not\n",
        "if 'required_education' not in df2.columns:\n",
        "    df2['required_education'] = None\n",
        "\n",
        "# Check if 'ColumnName' column exists in df, and add it with index row if not\n",
        "if 'required_experience' not in df2.columns:\n",
        "    df2['required_experience'] = None\n",
        "\n",
        "# Increment the 'job_id' column in df2 by the maximum value from df + 1\n",
        "df2['job_id'] = df2['job_id'].apply(lambda x: x + max_code + 1)\n",
        "\n",
        "# Add a new column 'has_company_logo' with random values of 0.0 or 1.0\n",
        "df2['has_company_logo'] = np.random.choice([0, 1], size=len(df2))\n",
        "\n",
        "# Add a new column 'has_questions' with random values of 0.0 or 1.0\n",
        "df2['has_questions'] = np.random.choice([0, 1], size=len(df2))\n",
        "\n",
        "# Add a new column 'telecommuting' with random values of 0.0 or 1.0\n",
        "df2['telecommuting'] = np.random.choice([0, 1], size=len(df2))\n",
        "\n",
        "# Rename the columns in the second dataframe to match the columns in the first dataframe\n",
        "df2.rename(columns={'job_title': 'title',\n",
        "                    'company_name': 'company_profile',\n",
        "                    'company_desc': 'description',\n",
        "                    'job_requirement': 'requirements',\n",
        "                    'salary': 'salary_range',\n",
        "                    'label': 'fraudulent'}, inplace=True)\n",
        "\n",
        "# Remove the 'job_desc' column\n",
        "\n",
        "\n",
        "df2 = df2.drop('job_desc', axis=1)\n",
        "\n",
        "column_order = ['job_id', 'title',\t'location',\t'department',\t'salary_range',\t'company_profile',\t'description',\t'requirements',\t'benefits',\t'telecommuting',\t'has_company_logo',\t'has_questions',\t'employment_type',\t'required_experience',\t'required_education',\t'industry',\t'function',\t'fraudulent']\n",
        "df2 = df2[column_order]\n",
        "\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-SjzFVROdoUS"
      },
      "outputs": [],
      "source": [
        "# Merge datas\n",
        "merged_df = pd.merge(df, df2, on=['job_id', 'title',\t'location',\t'department',\t'salary_range',\t'company_profile',\t'description',\t'requirements',\t'benefits',\t'telecommuting',\t'has_company_logo',\t'has_questions',\t'employment_type',\t'required_experience',\t'required_education',\t'industry',\t'function',\t'fraudulent'], how='outer')\n",
        "print(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-93zDAIYFja3"
      },
      "outputs": [],
      "source": [
        "# Import Scrapping File from local memory after scrapping process.\n",
        "df3=pd.read_csv('/content/jobs_linkedin.csv')\n",
        "\n",
        "# Find the maximum value in the 'Code' column of df\n",
        "max_code = merged_df['job_id'].max()\n",
        "\n",
        "# Increment the 'job_id' column in df2 by the maximum value from df + 1\n",
        "df3['job_id'] = df3['job_id'].apply(lambda x: x + max_code )\n",
        "\n",
        "# Convert multiple columns to object type\n",
        "columns_to_convert = ['department', 'salary_range', 'description', 'requirements', 'benefits', 'required_education']\n",
        "df3[columns_to_convert] = df3[columns_to_convert].astype(str)\n",
        "\n",
        "# Remove the 'Link' column\n",
        "#df2 = df2.drop('Link')\n",
        "\n",
        "column_order = ['job_id', 'title',\t'location',\t'department',\t'salary_range',\t'company_profile',\t'description',\t'requirements',\t'benefits',\t'telecommuting',\t'has_company_logo',\t'has_questions',\t'employment_type',\t'required_experience',\t'required_education',\t'industry',\t'function',\t'fraudulent']\n",
        "df3 = df3[column_order]\n",
        "\n",
        "# Merge datas\n",
        "final_merged_df = pd.merge(merged_df, df3, on=['job_id', 'title',\t'location',\t'department',\t'salary_range',\t'company_profile',\t'description',\t'requirements',\t'benefits',\t'telecommuting',\t'has_company_logo',\t'has_questions',\t'employment_type',\t'required_experience',\t'required_education',\t'industry',\t'function',\t'fraudulent'], how='outer')\n",
        "print(final_merged_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12OIlUF27OOQ"
      },
      "source": [
        "Il y a au total 18 variables, et elles peuvent être réparties en quatre catégories : Texte, Catégorique, Numérique et Autre. les caractéristiques qui correspondent à chaque catégorie:\n",
        "\n",
        "**Text** : Title, Location, Department, Company Profile, Description, Requirements, Benefits.\n",
        "\n",
        "**Categorical** :  Employment Type, Required Experience, Required Education, Industry, Function.\n",
        "\n",
        "**Numeric** :  Job Id, Has Company Logo, Telecommuting, Has Questions, Fraudulent.\n",
        "\n",
        "**Other** :  Salary Range.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drcwCnXO_OHc"
      },
      "source": [
        "                         *Text Variables*\n",
        "\n",
        "**Title**: title of the job ad entry (11,231).\n",
        "\n",
        " **Location**: geographical location of the job ad (3105).\n",
        "\n",
        "**Department**: corporate department (1337).\n",
        "\n",
        "**Company Profile**: brief company description (1709).\n",
        "\n",
        "**Description**: details description of the job ad (14,801).\n",
        "\n",
        "**Requirements**: enlisted requirements for the job opening (11,968).\n",
        "\n",
        "**Benefits**: enlisted benefits offered by the employer (6205).\n",
        "\n",
        "**Salary Range**: indicative salary range (874).\n",
        "\n",
        "*Note: this value is a string in the original dataset but will be split into two numeric values during pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJgTz6BAfwW"
      },
      "source": [
        "              *Categorical Variables*\n",
        "\n",
        "**Employment Type**: full-time, part-time, etc.\n",
        "\n",
        "**Required Experience**: entry-level, etc.\n",
        "\n",
        "**Required Educatio**n: Bachelor, etc.\n",
        "\n",
        "**Industry**: automotive, IT, etc.\n",
        "\n",
        " **Function**: consulting, research, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwQR01MABOZ0"
      },
      "source": [
        "                            *Numeric Variables*\n",
        "\n",
        "**Job Id**: identification number for the job posting (18,091).\n",
        "\n",
        " **Telecommuting**: indicates whether posting mentions telecommuting.\n",
        "\n",
        "**Has Company Logo**: indicates whether company logo is present.\n",
        "\n",
        "**Has Questions**: indicates whether screening questions are present.\n",
        "\n",
        "**Fraudulent**: indicates whether posting is fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4Ox2lIUyyFX"
      },
      "source": [
        "# Exploring the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7WxLNK65y-zS"
      },
      "outputs": [],
      "source": [
        "final_merged_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSQaC3mP8bzl"
      },
      "source": [
        "* Total Entries: The dataset has a total of 17,880 entries.\n",
        "\n",
        "* The columns of the dataset\n",
        "\n",
        "* Missing Values: Some columns have missing values, such as 'location,' 'department,' 'salary_range,' 'company_profile,' and others. The number of non-null entries in each column is provided.\n",
        "\n",
        "* Data Types: The data types include integers for numerical columns and objects for textual columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WpLOfC2azNDP"
      },
      "outputs": [],
      "source": [
        "# get unique values from the dataset\n",
        "final_merged_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hp9x3MNs0mH_"
      },
      "outputs": [],
      "source": [
        "# Count the sum of missing values for each column\n",
        "final_merged_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zpcoit2V2dhz"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of unique values in the 'fraudulent' column\n",
        "final_merged_df['fraudulent'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJeP4VkG6bNB"
      },
      "source": [
        "*   Text columns are title, location, department, company profile, description, requirements, and benefits, industry, function.\n",
        "* Categorical columns are employment type, required experience, and required   education\n",
        "* Numeric variables are salary (low/high), work_remote, has company logo, and has questions\n",
        "* Column to Predict is fraudulent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oASZ-BZp6v1d"
      },
      "outputs": [],
      "source": [
        "#separate columns based on their type\n",
        "text_cols = ['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits']\n",
        "categorical_cols = ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
        "numeric_cols = ['work_remote', 'has_company_logo', 'has_questions', 'salary_low', 'salary_high']\n",
        "col_to_predict = ['fraudulent']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXmKz7yTUPOO"
      },
      "source": [
        "*italicized text*### Cleaning Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnZXLW8hUere"
      },
      "source": [
        "Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9yK4eSAUUino"
      },
      "outputs": [],
      "source": [
        "def move_column(df, col):\n",
        "  df['Temp_Col'] = df[col]\n",
        "  df.drop(columns=[col], inplace=True)\n",
        "  df.rename(columns={'Temp_Col': col}, inplace=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LRj7fw8UUnVq"
      },
      "outputs": [],
      "source": [
        "df['employment_type'].fillna('No Data', inplace=True)\n",
        "df['required_experience'].fillna('No Data', inplace=True)\n",
        "df['required_education'].fillna('No Data', inplace=True)\n",
        "df['industry'].fillna('No Data', inplace=True)\n",
        "df['function'].fillna('No Data', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-H4uovLjU68i"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2hXBGPnJU_Um"
      },
      "outputs": [],
      "source": [
        "df.notna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YvjRvB55VCA0"
      },
      "outputs": [],
      "source": [
        "df[df['description'].isna()] #only 1 row with an empty description -- the post only has title and location and it is a fraud post --> keeping it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6H60fSzlVrtP"
      },
      "outputs": [],
      "source": [
        "#rows that are entirely null in the text columns\n",
        "null_text = df[(df['location'].isna()) & (df['department'].isna()) & (df['company_profile'].isna()) & (df['requirements'].isna()) & (df['benefits'].isna())] # 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits'\n",
        "print(f\"There are {null_text.shape[0]} rows where all text columns aside from 'title' and 'description' are empty. Of these rows, {null_text['fraudulent'].sum()} are fraudulent posts.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFdOzyB3V2jX"
      },
      "source": [
        "There are 19 rows where all text columns aside from 'title' and 'description' are empty. Of these rows, 12 are fraudulent posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VqTL-MLcV6P1"
      },
      "outputs": [],
      "source": [
        "for col in text_cols: df[col].fillna(value=\" \", inplace=True)\n",
        "print(f\"Max length of '{col}': {df[col].map(len).max()}\")\n",
        "    #get maximum number of characters in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rIFD2hULWA92"
      },
      "outputs": [],
      "source": [
        "#combine all text into 1 column - full_text\n",
        "df['full_text'] = df['title'] + \" \" + df['location'] + \" \" + df['department'] + \" \" + df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits']\n",
        "df['full_text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fQsX6w5pWEzB"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"Min length of 'full text': {df['full_text'].map(len).min()}\")\n",
        "print(f\"Max length of 'full text': {df['full_text'].map(len).max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eGE8CXIuWG0_"
      },
      "outputs": [],
      "source": [
        "def update_text(new_df):\n",
        "  new_df['full_text'] = new_df['full_text'].str.replace(pat='US', repl='USA', case=True)\n",
        "  new_df['location'] = new_df['location'].str.replace(pat='US', repl='USA', case=True)\n",
        "  return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DK45cgg3WIzf"
      },
      "outputs": [],
      "source": [
        "# update US with USA so it does not get mixed up with the word 'us'\n",
        "df = update_text(df) #replace urls, email, phone numbers (contact details) ?? maybe presence/absence could indicate a fake post? #\n",
        "df['full_text'] = df['full_text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', ' ', regex=True).replace(r'#PHONE\\S+', '', regex=True).replace(r'#EMAIL\\S+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KrM87cIpWKmf"
      },
      "outputs": [],
      "source": [
        "#separate 2 separate words that have been put together (i.e. PinterestLoves -> Pinterest Loves)\n",
        "def space_words(all_text):\n",
        "  import re\n",
        "  #print('start', all_text)\n",
        "  result = re.sub('(?<=[A-Za-z])(?=[A-Z][a-z])', '~', all_text)\n",
        "  result = re.split('~', result)\n",
        "  result = ' '.join(result)\n",
        "  all_text = result # print('end',all_text)\n",
        "  return all_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "du_LaBVpWMil"
      },
      "outputs": [],
      "source": [
        "texts = ['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'employment_type', 'required_experience', 'required_education', 'industry', 'function', 'full_text']\n",
        "for col in texts:\n",
        "   df[col] = df[col].apply(space_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F4fcYehvWSX_"
      },
      "outputs": [],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DhvyQlB9WYtr"
      },
      "outputs": [],
      "source": [
        "def get_unique_words(new_df, col):\n",
        "    unique_words = []\n",
        "    idx = list(new_df.index.values)\n",
        "    for i in idx:\n",
        "        if new_df[col][i]:  # Check if the value is not None\n",
        "            unique_words.extend(new_df[col][i].split())\n",
        "    return unique_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8_yqLwLaWagN"
      },
      "outputs": [],
      "source": [
        "for col in texts:\n",
        "  print(f'Number of total words in {col}: {len(get_unique_words(df, col))}')\n",
        "  print(f'Number of unique words in {col}: {len(set(get_unique_words(df, col)))}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tbeu1bmWiIE"
      },
      "source": [
        "Salary Range Column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EPRW722AWkn_"
      },
      "outputs": [],
      "source": [
        "salary_df = df['salary_range'].str.split(pat='-', n=-1, expand=True)\n",
        "#separate salary range into two columns\n",
        "salary_df[0].unique()[90:100] #months (strings) are included as salaries due to csv interpretation of the salary range\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YnLI5BjaWmzx"
      },
      "outputs": [],
      "source": [
        "#convert the months in the salary columns into integers\n",
        "months_to_int = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "for i in range(salary_df[0].shape[0]):\n",
        "  if salary_df[0][i] in months_to_int.keys(): salary_df[0][i] = months_to_int[salary_df[0][i]]\n",
        "for i in range(salary_df[1].shape[0]):\n",
        "  if salary_df[1][i] in months_to_int.keys(): salary_df[1][i] = months_to_int[salary_df[1][i]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IWl6eZdiWo8c"
      },
      "outputs": [],
      "source": [
        "#verify conversion of string months to integers\n",
        "salary_df[0].unique()[90:100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "axRY-apnWrNM"
      },
      "outputs": [],
      "source": [
        "salary_df.fillna(value=-1, inplace=True)\n",
        "salary_df[0] = np.array(salary_df[0], dtype='int64')\n",
        "salary_df[1] = np.array(salary_df[1], dtype='int64')\n",
        "#move the min/max salary columns to the main dataframe\n",
        "df['salary_low'] = salary_df[0]\n",
        "df['salary_high'] = salary_df[1]\n",
        "df.drop(columns= ['salary_range'], inplace=True)\n",
        "df.drop(columns= ['job_id'], inplace=True)\n",
        "df['salary_low'].replace(-1, np.nan, inplace=True)\n",
        "df['salary_high'].replace(-1, np.nan, inplace=True)\n",
        "df['salary_low'] = df['salary_low'].astype('Int64')\n",
        "df['salary_high'] = df['salary_high'].astype('Int64')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MS7fCINwWtNZ"
      },
      "outputs": [],
      "source": [
        "df[df['salary_low'].notnull() & df['salary_high'].notnull()][:3] #some examples showing that the salary was converted back to an int value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRwvOjp-WvX6"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Replace Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h7cJUCU6WxHN"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "#split df into train/val/test so I can use the mean of salary_low & salary_high from the training data\n",
        "print('dataframe shape:',df.shape)\n",
        "train, test_x = train_test_split(df, train_size=0.8, random_state=1, shuffle=True, stratify=df.fraudulent.values)\n",
        "print(\"train shape:\",train.shape)\n",
        "print('test shape:',test_x.shape)\n",
        "train_x, val_x = train_test_split(train, train_size = 0.8, random_state=1, shuffle = True, stratify=train.fraudulent.values)\n",
        "print(\"train_x shape:\",train_x.shape)\n",
        "print('val shape:',val_x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QerKlLtLXSvn"
      },
      "outputs": [],
      "source": [
        "train_x['employment_type'].isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UTL14uSXkRZM"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IuWoPCzKXZiz"
      },
      "outputs": [],
      "source": [
        "train_x.groupby('employment_type').mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Haa6nma5XbsI"
      },
      "outputs": [],
      "source": [
        "salary_means = {}\n",
        "employment_types = list(train_x['employment_type'].unique())\n",
        "employment_types.sort()\n",
        "employment_types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nWUNb3YIXdXN"
      },
      "outputs": [],
      "source": [
        "low_means = list(train_x.groupby('employment_type')['salary_low'].mean())\n",
        "high_means = list(train_x.groupby('employment_type')['salary_high'].mean())\n",
        "salary_means = {}\n",
        "for i in range(len(employment_types)):\n",
        "  salary_means[employment_types[i]] = [int(low_means[i]), int(high_means[i])]\n",
        "print(\"List of Means (from train_x dataset):\", salary_means)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XRnvmqSUXfqs"
      },
      "outputs": [],
      "source": [
        "for et in employment_types: temp = df[df['employment_type'] == et] #separate the group temp['salary_low'].fillna(salary_means[et][0], inplace=True) temp['salary_high'].fillna(salary_means[et][1], inplace=True) df.update(temp, overwrite=False) df['salary_low'] = df['salary_low'].astype('int64') df['salary_high'] = df['salary_high'].astype('int64') print(df.shape) df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4r_XYy_XXibn"
      },
      "outputs": [],
      "source": [
        "df.info() #confirms that the salary columns are int64 and not float64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ChHFbcQXoee"
      },
      "source": [
        "Additional Text Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0b-XtBiQXqZ9"
      },
      "outputs": [],
      "source": [
        "df_preproc_done = df.copy()\n",
        "df_preproc_done.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P4wlTAOXXsQ7"
      },
      "outputs": [],
      "source": [
        "# combine all text columns into the title column # drop all text columns except full_text # rename 'title' column to 'full_text'\n",
        "df['title'] = df['full_text']\n",
        "df.drop(columns=['location', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'full_text'], inplace=True)\n",
        "df.rename(columns={'title': 'full_text'}, inplace=True) #put fraud column at the end of the dataframe\n",
        "df = move_column(df, 'fraudulent')\n",
        "df.head(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACIAg6i8Xuh4"
      },
      "source": [
        "Completed:\n",
        "\n",
        "\n",
        "*   replaced NA values in categorical columns with 'No Data'\n",
        "*   created 'full_text' column with all textual columns combined\n",
        "*   split the 'salary_range' column into 2 for the range --> salary_low, salary_high\n",
        "*   replace 'months' in salary columns with integers\n",
        "*   replace NA values in salary columns with -1, create new columns in main dataframe for salary (low/high), replace -1 with NaN and cast to type Integer64\n",
        "*   move full_text to the front of the dataframe, move fraudulent to the end of the dataframe; and rename both columns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5db16aa83304802a3e19aab154ab008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_1e2613cd0b1f4c5f9227000319e23bef",
            "metadata": [
              {
                "name": "jobs_linkedin.csv",
                "type": "text/csv",
                "size": 19846667,
                "lastModified": 1708463182674
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_5c5e293930f9484f9ca4a9560effcee0"
          }
        },
        "1e2613cd0b1f4c5f9227000319e23bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5e293930f9484f9ca4a9560effcee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}