# -*- coding: utf-8 -*-
"""DataScraping_UK.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_-jIoda4P-B49p1oQzyS08BXrbgxLHiB
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from google.colab import files

# URL de la page web contenant les liens vers les fichiers CSV
url = "https://tfl.gov.uk/corporate/publications-and-reports/road-safety?fbclid=IwAR3gtH-KcxQ2BC7m1wMVD6AsFZn74J_SJh6ntnumeFXUAwuU69y-XrX-gGo#on-this-page-1"

# Récupérer le contenu de la page web
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# Extraire les liens vers les fichiers CSV
csv_links = [urljoin(url, link['href']) for link in soup.find_all('a', {'class': 'document-download-wrap csv'})]

# Télécharger chaque fichier CSV
for csv_link in csv_links:
    filename = csv_link.split("/")[-1]

    # Vérifier si le lien commence par "http" ou "https"
    if csv_link.startswith(("http", "https")):
        csv_data = requests.get(csv_link).text

        # Enregistrer le fichier CSV dans l'environnement Colab
        with open(filename, 'w') as f:
            f.write(csv_data)

        # Télécharger le fichier CSV dans l'environnement Colab
        files.download(filename)
    else:
        print(f"Le lien ne commence pas par 'http' ou 'https': {csv_link}")