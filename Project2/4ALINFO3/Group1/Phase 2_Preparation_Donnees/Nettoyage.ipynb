{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24bbb083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def valeur_plus_frequente(liste):\n",
    "    # Filtrer les valeurs qui sont des chaînes de caractères et différentes de None\n",
    "    valeurs_str = [valeur for valeur in liste if (isinstance(valeur, str) \n",
    "                    or (isinstance(valeur, float) \n",
    "                    and not math.isnan(valeur))) and valeur is not None \n",
    "                    and valeur != \"nan\" and valeur != 0.0]\n",
    "    # Vérifier si la liste filtrée est vide\n",
    "    if not valeurs_str:\n",
    "        return None\n",
    "    # Utiliser Counter pour compter le nombre d'occurrences de chaque élément\n",
    "    compteur = Counter(valeurs_str)\n",
    "    # Utiliser max() avec une fonction lambda pour obtenir l'élément avec le plus grand nombre d'occurrences\n",
    "    valeur_plus_frequente = max(compteur, key=compteur.get)\n",
    "    return valeur_plus_frequente\n",
    "\n",
    "# Définir une fonction pour nettoyer chaque valeur de la colonne\n",
    "def clean_string(encoded_string):\n",
    "    if isinstance(encoded_string, str):  # Vérifiez si la valeur est une chaîne de caractères\n",
    "        # Décoder la chaîne depuis l'UTF-8 avec 'replace' pour gérer les caractères non décodables\n",
    "        decoded_string = encoded_string.encode('latin1').decode('utf-8', errors='replace')\n",
    "        # Réencoder la chaîne en latin1\n",
    "        cleaned_string = decoded_string.encode('latin1')\n",
    "    else:\n",
    "        return encoded_string  # Retourner la valeur telle quelle si elle n'est pas une chaîne de caractères\n",
    "\n",
    "def detect_csv_separator(file_path):\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        dialect = csv.Sniffer().sniff(csvfile.read(1024))  # Reads the first 1024 bytes to detect the delimiter\n",
    "        return dialect.delimiter\n",
    "    \n",
    "    \n",
    "# Define a function to clean and convert the data\n",
    "def clean_and_convert(data):\n",
    "    # Check if data is null or empty\n",
    "    if data is None or data == '':\n",
    "        return '-1'\n",
    "    # Convert data to string if it's not already\n",
    "    data_str = str(data)\n",
    "    # Remove non-numeric characters\n",
    "    cleaned_data = ''.join(filter(str.isdigit, data_str))\n",
    "    return cleaned_data\n",
    "\n",
    "def categorize_vehicle(code_vehicule):\n",
    "    if code_vehicule in [1, 2, 3, 10, 11, 12, 41, 42, 43, 50, 60, 80]:\n",
    "        return 1  # 'Passagers Véhicules'\n",
    "    elif code_vehicule in [4, 5, 6, 30, 31, 32, 33, 34, 35, 36]:\n",
    "        return 2  # 'Motocyclettes'\n",
    "    elif code_vehicule in [7, 8, 9]:\n",
    "        return 3  # 'Camions légers'\n",
    "    elif code_vehicule in [13, 14, 15, 16, 17]:\n",
    "        return 4  # 'Gros Camions'\n",
    "    elif code_vehicule in [18, 19, 20, 21, 37, 38, 39, 40]:\n",
    "        return 5  # 'Transport Public'\n",
    "    else:\n",
    "        return 0  # 'Autres/Inconnus'\n",
    "\n",
    "def actp(input):\n",
    "    return str(input)[:1]\n",
    " \n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6e54218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Downloads\\caracteristiques-2017.csv\n",
      ",\n",
      "../Downloads\\caracteristiques-2018.csv\n",
      ",\n",
      "../Downloads\\caracteristiques-2019.csv\n",
      ";\n",
      "../Downloads\\caracteristiques-2020.csv\n",
      ";\n",
      "../Downloads\\carcteristiques-2021.csv\n",
      ";\n",
      "../Downloads\\carcteristiques-2022.csv\n",
      ";\n",
      "Accident_Id     int64\n",
      "jour            int64\n",
      "mois            int64\n",
      "an              int64\n",
      "hrmn           object\n",
      "lum             int64\n",
      "dep            object\n",
      "com            object\n",
      "agg             int64\n",
      "int             int64\n",
      "atm             int64\n",
      "col             int64\n",
      "adr            object\n",
      "lat            object\n",
      "long           object\n",
      "dtype: object\n",
      "Index(['float_columns Num_Acc', 'float_columns atm', 'float_columns col'], dtype='object')\n",
      "Index(['string_columns hrmn', 'string_columns adr', 'string_columns lat',\n",
      "       'string_columns long'],\n",
      "      dtype='object')\n",
      "valeur_plus_frequente adr AUTOROUTE A86\n",
      "valeur_plus_frequente lat 4800000.0\n",
      "valeur_plus_frequente long 228547.0\n",
      "End Caracteristiques\n"
     ]
    }
   ],
   "source": [
    "#caracteristique\n",
    "# Get a list of all CSV files in the directory\n",
    "files = glob.glob('../Downloads/car*.csv'\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "# Loop through each file and append its data to the combined DataFrame\n",
    "for file in files:\n",
    "    print(file)\n",
    "    # Read the first row of the file to infer data types\n",
    "    separator = detect_csv_separator(file)\n",
    "    #dtypes = pd.read_csv(file, nrows=1,encoding='ansi').dtypes.to_dict()\n",
    "    print(separator)\n",
    "    # Read the entire CSV file using inferred data types\n",
    "    df = pd.read_csv(file, encoding='ansi', sep=separator, quotechar='\"')\n",
    "    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "    \n",
    "# Now 'combined_data' contains data from all CSV files\n",
    "combined_data['Num_Acc'] = combined_data['Num_Acc'].fillna(combined_data['Accident_Id'])\n",
    "combined_data = combined_data.drop(columns=['Accident_Id'])\n",
    "\n",
    "# Supprimer les colonnes \"gps\" et \"dep\" et \"com\"\n",
    "combined_data.drop(columns=['gps', 'dep', 'com'], inplace=True)\n",
    "\n",
    "float_columns = combined_data.select_dtypes(include=['float']).columns\n",
    "combined_data[float_columns] = combined_data[float_columns].fillna(0)\n",
    "combined_data[float_columns] = combined_data[float_columns].astype(np.int64)\n",
    "\n",
    "string_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "adr_freq = str(valeur_plus_frequente(combined_data['adr']))\n",
    "print('valeur_plus_frequente adr '+ adr_freq)\n",
    "combined_data['adr'].fillna(value=adr_freq, inplace=True)\n",
    "lat_freq = str(valeur_plus_frequente(combined_data['lat']))\n",
    "print('valeur_plus_frequente lat '+ lat_freq)\n",
    "combined_data['lat'].fillna(value=lat_freq, inplace=True)\n",
    "long_freq = str(valeur_plus_frequente(combined_data['long']))\n",
    "print('valeur_plus_frequente long '+ long_freq)\n",
    "combined_data['long'].fillna(value=long_freq, inplace=True)\n",
    "\n",
    "# Chemin du fichier de sortie\n",
    "output_file = '../csv/caracteristiques.csv'\n",
    "\n",
    "# Vérifier si le fichier existe\n",
    "if os.path.exists(output_file):\n",
    "    # Si le fichier existe, le supprimer\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Enregistrer le nouveau fichier CSV\n",
    "combined_data.to_csv(output_file, sep='|', index=False)\n",
    "print('End Caracteristiques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64a82e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Downloads\\usagers-2017.csv\n",
      ",\n",
      "../Downloads\\usagers-2018.csv\n",
      ",\n",
      "../Downloads\\usagers-2019.csv\n",
      ";\n",
      "../Downloads\\usagers-2020.csv\n",
      ";\n",
      "../Downloads\\usagers-2021.csv\n",
      ";\n",
      "../Downloads\\usagers-2022.csv\n",
      ";\n",
      "Num_Acc          int64\n",
      "id_usager       object\n",
      "id_vehicule     object\n",
      "num_veh         object\n",
      "place            int64\n",
      "catu             int64\n",
      "grav             int64\n",
      "sexe             int64\n",
      "an_nais        float64\n",
      "trajet           int64\n",
      "secu1            int64\n",
      "secu2            int64\n",
      "secu3            int64\n",
      "locp             int64\n",
      "actp            object\n",
      "etatp            int64\n",
      "dtype: object\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "760367      0\n",
      "760368      0\n",
      "760369      0\n",
      "760370     -1\n",
      "760371     -1\n",
      "Name: actp, Length: 760372, dtype: object\n",
      "Index(['place', 'trajet', 'locp', 'etatp', 'an_nais'], dtype='object')\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "760367    0\n",
      "760368    0\n",
      "760369    0\n",
      "760370     \n",
      "760371     \n",
      "Name: actp, Length: 760372, dtype: object\n",
      "end Usager\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#usagers\n",
    "# Get a list of all CSV files in the directory\n",
    "files = glob.glob('../Downloads/usagers*.csv')\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file and append its data to the combined DataFrame\n",
    "for file in files:\n",
    "    print(file)\n",
    "    # Read the first row of the file to infer data types\n",
    "    separator = detect_csv_separator(file)\n",
    "    #dtypes = pd.read_csv(file, nrows=1).dtypes.to_dict()\n",
    "    print(separator)\n",
    "    # Read the entire CSV file using inferred data types\n",
    "    df = pd.read_csv(file, encoding='ansi', sep=separator, quotechar='\"')\n",
    "\n",
    "    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "    \n",
    "# Now 'combined_data' contains data from all CSV files\n",
    "# Supprimer les colonnes \"secu\", \"secu1\", \"secu2\" et \"secu3\"\n",
    "combined_data.drop(columns=['secu', 'secu1', 'secu2', 'secu3'], inplace=True)\n",
    "\n",
    "# Replace the problematic data in the column\n",
    "combined_data['id_vehicule'] = combined_data['id_vehicule'].apply(clean_and_convert)\n",
    "combined_data['id_usager'] = combined_data['id_usager'].apply(clean_and_convert)\n",
    "\n",
    "column_types = df.dtypes\n",
    "print(column_types)\n",
    "print(combined_data['actp'])\n",
    "float_columns = combined_data.select_dtypes(include=['float']).columns\n",
    "print(float_columns)\n",
    "combined_data[float_columns] = combined_data[float_columns].fillna(0)\n",
    "combined_data[float_columns] = combined_data[float_columns].astype(np.int64)\n",
    "combined_data['actp'] = combined_data['actp'].apply(actp)\n",
    "print(combined_data['actp'])\n",
    "string_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "combined_data[string_columns] = combined_data[string_columns].fillna(value='na')\n",
    "\n",
    "combined_data.to_csv('../csv/usagers.csv', sep='|', index=False)\n",
    "\n",
    "print('end Usager')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c849c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Downloads\\vehicules-2017.csv\n",
      ",\n",
      "../Downloads\\vehicules-2018.csv\n",
      ",\n",
      "../Downloads\\vehicules-2019.csv\n",
      ";\n",
      "../Downloads\\vehicules-2020.csv\n",
      ";\n",
      "../Downloads\\vehicules-2021.csv\n",
      ";\n",
      "../Downloads\\vehicules-2022.csv\n",
      ";\n",
      "Num_Acc          int64\n",
      "id_vehicule     object\n",
      "num_veh         object\n",
      "senc             int64\n",
      "catv             int64\n",
      "obs              int64\n",
      "obsm             int64\n",
      "choc             int64\n",
      "manv             int64\n",
      "motor            int64\n",
      "occutc         float64\n",
      "dtype: object\n",
      "End Vehicules\n"
     ]
    }
   ],
   "source": [
    "#vehicules\n",
    "# Get a list of all CSV files in the directory\n",
    "files = glob.glob('../Downloads/vehicules*.csv')\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file and append its data to the combined DataFrame\n",
    "for file in files:\n",
    "    print(file)\n",
    "    # Read the first row of the file to infer data types\n",
    "    separator = detect_csv_separator(file)\n",
    "    #dtypes = pd.read_csv(file, nrows=1).dtypes.to_dict()\n",
    "    print(separator)\n",
    "    # Read the entire CSV file using inferred data types\n",
    "    df = pd.read_csv(file, encoding='ansi', sep=separator, quotechar='\"')\n",
    "    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "# Now 'combined_data' contains data from all CSV files\n",
    "# Replace the problematic data in the column\n",
    "combined_data['id_vehicule'] = combined_data['id_vehicule'].apply(clean_and_convert)\n",
    "\n",
    "# Aggregation \n",
    "# 1 - 'Passagers Véhicules'[1, 2, 3, 10, 11, 12, 41, 42, 43, 50, 60, 80]\n",
    "# 2 - 'Motocyclettes' [4, 5, 6, 30, 31, 32, 33, 34, 35, 36]\n",
    "# 3 - 'Camions légers' [7, 8, 9]\n",
    "# 4 - 'Gros Camions' [13, 14, 15, 16, 17]\n",
    "# 5 - 'Transport Public' [18, 19, 20, 21, 37, 38, 39, 40]\n",
    "# 0 - 'Autres/Inconnus' [90]\n",
    "combined_data['catv'] = combined_data['catv'].apply(categorize_vehicle)\n",
    "\n",
    "float_columns = combined_data.select_dtypes(include=['float']).columns\n",
    "combined_data[float_columns] = combined_data[float_columns].fillna(0)\n",
    "combined_data[float_columns] = combined_data[float_columns].astype(np.int64)\n",
    "string_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "combined_data[string_columns] = combined_data[string_columns].fillna(value='NA')\n",
    "print(df.dtypes)\n",
    "# Chemin du fichier de sortie\n",
    "output_file = '../csv/vehicules.csv'\n",
    "\n",
    "# Vérifier si le fichier existe\n",
    "if os.path.exists(output_file):\n",
    "    # Si le fichier existe, le supprimer\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Enregistrer le nouveau fichier CSV\n",
    "combined_data.to_csv(output_file, sep='|', index=False)\n",
    "print('End Vehicules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lieux\n",
    "# Get a list of all CSV files in the directory\n",
    "files = glob.glob('../Downloads/lieux*.csv')\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file and append its data to the combined DataFrame\n",
    "for file in files:\n",
    "    print(file)\n",
    "    # Read the first row of the file to infer data types\n",
    "    separator = detect_csv_separator(file)\n",
    "    #dtypes = pd.read_csv(file, nrows=1).dtypes.to_dict()\n",
    "    print(separator)\n",
    "    # Read the entire CSV file using inferred data types\n",
    "    df = pd.read_csv(file, encoding='ansi', sep=separator, quotechar='\"',low_memory=False)\n",
    "    df['voie'] = df['voie'].astype(str)\n",
    "    # Fill missing values with a specific value, e.g., 'Unknown'\n",
    "    df['voie'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "# Now 'combined_data' contains data from all CSV files\n",
    "# Supprimer les colonnes \"v1\" et \"v2\" et \"env1\"\n",
    "combined_data.drop(columns=['v1', 'v2', 'env1', 'pr' , 'pr1', 'nbv'], inplace=True)\n",
    "\n",
    "float_columns = combined_data.select_dtypes(include=['float']).columns\n",
    "print(float_columns)\n",
    "combined_data[float_columns] = combined_data[float_columns].fillna(0)\n",
    "combined_data[float_columns] = combined_data[float_columns].astype(np.int64)\n",
    "string_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "print(string_columns)\n",
    "\n",
    "voie_freq = str(valeur_plus_frequente(combined_data['voie']))\n",
    "print('valeur_plus_frequente voie '+ voie_freq)\n",
    "combined_data['voie'].fillna(value=voie_freq, inplace=True)\n",
    "\n",
    "lartpc_freq = str(valeur_plus_frequente(combined_data['lartpc']))\n",
    "print('valeur_plus_frequente lartpc '+ lartpc_freq)\n",
    "combined_data['lartpc'].fillna(value=lartpc_freq, inplace=True)\n",
    "\n",
    "larrout_freq = str(valeur_plus_frequente(combined_data['larrout']))\n",
    "print('valeur_plus_frequente larrout '+ larrout_freq)\n",
    "combined_data['larrout'].fillna(value=larrout_freq, inplace=True)\n",
    "\n",
    "combined_data.to_csv('../csv/lieux.csv', sep='|',  index=False)\n",
    "print('end lieux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e346ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
